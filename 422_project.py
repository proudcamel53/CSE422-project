# -*- coding: utf-8 -*-
"""422_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sqpH1Wg5UgBnqQN2qOz-KVoFAZcY-Slu
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler,MinMaxScaler
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.cluster import KMeans
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc

"""# New Section"""

df=pd.read_csv("/content/consumer_classification_dataset.csv")
df.head(500)

# Description dataset
#how many features
print(f"there are {df.shape[1]} features in the dataset")

# classification or regression
print("This is a classification problem because the target variable churn is categorical as in 0 means did not churn and 1 means churn")

# how many data point
print(f"there are {df.shape[0]} data points in the dataset")

#what type of feature
print("the numerical types are ")

"""correlation of all features by using heastmap from seaborn library[link text](https://)"""

numerical_data = df.select_dtypes(include='number')
numerical_features = numerical_data.columns.tolist()

# Correlation matrix of numerical features
co_matrix = numerical_data.corr()

# Plot heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(co_matrix, annot=True, cmap='coolwarm', fmt=".2f", cbar=True)
plt.title('Correlation Matrix of Numerical Features')
plt.show()

# equal number of instance
df["Churn"].value_counts()

print("dataset is balanced as it is nearly equal")

labels=["No Churn","Churn"]
values=df["Churn"].value_counts()
plt.pie(values,labels=labels,autopct="%1.1f%%")
plt.show()

#bar chart of N classes
n = df['Churn'].value_counts()
print(n)

plt.figure(figsize=(4,3)) # Make the bar chart smaller
n.plot(kind='bar', figsize=(6,4))
plt.title("Class Distribution of Churn")
plt.xlabel("Churn")
plt.ylabel("Count")
plt.show()

#eda
#Barplot of unique value counts in every categorical features
n = ["Gender", "Marital_Status", "Device_Used"]
for i in n:
  plt.figure(figsize=(4,3)) # to make the plots smaller
  plt.title(f"{i} vs churn")
  sns.countplot(x=i, hue="Churn", data=df)
  plt.xlabel(i)
  plt.ylabel("Count")
  plt.show()
  print()

# dataset processing
#faults: null values and cat values
# null
print(df.isnull().sum())
#cat values
non_numeric_cols=df.select_dtypes(exclude=["number","bool_"]).columns.tolist()
print(non_numeric_cols)

"""dealing with null values"""

null_rows=df.isnull().any(axis=1).sum()
print(null_rows)

null_cols=df.columns[df.isnull().any()].tolist()
print(null_cols)

for col in null_cols:
  if df[col].dtype==df["Gender"].dtype:
    mode=df[col].mode()[0]
    df[col]=df[col].fillna(mode)
  else:
    df[col]=df[col].fillna(df[col].median())

df.isnull().sum()

#no null values
print(df.head(10))

"""dealing with categorical values

"""

print(non_numeric_cols)

from sklearn.preprocessing import LabelEncoder
L= LabelEncoder()
for i in non_numeric_cols: #all the categorical colummns
  df[i]=L.fit_transform(df[i])

print(df.head(10))

df.dtypes

"""feature scaling

"""

for col in df.columns.to_list():
  col_var=np.var(df[col])
  print(f"{col}: {round(col_var,2)}")

#scaling
feature=df.drop("Churn",axis=1).columns.to_list()
print(feature)
scaler=StandardScaler()
df[feature]=scaler.fit_transform(df[feature])
df.head(10)

"""dataset splitting

"""

from sklearn.model_selection import train_test_split
X=df.drop(columns=["Churn"])
y=df["Churn"]
x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)
#80 percent train and 20 percent test.

from sklearn.cluster import KMeans

# K-Means (Note: K-Means is an unsupervised algorithm, so it will be used for clustering, not classification on the labeled data)
# For demonstration purposes, we will apply it to the training data and see the cluster assignments.
# In a real scenario, you might use K-Means for customer segmentation before building a churn model.
kmeans = KMeans(n_clusters=2, random_state=0, n_init=10) # Assuming 2 clusters for churn/no churn
kmeans.fit(x_train)
kmeans_labels = kmeans.labels_
print("\nK-Means Clustering on Training Data:")
print("Cluster assignments for the first 10 training samples:", kmeans_labels[:10])

"""Training with different models"""

# Logistic Regression
lr_model = LogisticRegression(random_state=0)
lr_model.fit(x_train, y_train)
lr_pred = lr_model.predict(x_test)

print("Classification Report:\n", classification_report(y_test, lr_pred))
# print("Confusion Matrix:\n", confusion_matrix(y_test, lr_pred))

#Decision Tree
dt_model = DecisionTreeClassifier(random_state=0)
dt_model.fit(x_train, y_train)
dt_pred = dt_model.predict(x_test)

print("Classification Report:\n", classification_report(y_test, dt_pred))
# print("Confusion Matrix:\n", confusion_matrix(y_test, dt_pred))

# Neural Network
nn_model = MLPClassifier(random_state=0)
nn_model.fit(x_train, y_train)
nn_pred = nn_model.predict(x_test)

print("Classification Report:\n", classification_report(y_test, nn_pred))
# print("Confusion Matrix:\n", confusion_matrix(y_test, nn_pred))

"""Accuracy

"""

print("Logistic Regression Classifier Accuracy:")
print("Accuracy:", accuracy_score(y_test, lr_pred))

print("Decision Tree Classifier Accuracy:")
print("Accuracy:", accuracy_score(y_test, dt_pred))

print("Neural Network Classifier Accuracy:")
print("Accuracy:", accuracy_score(y_test, nn_pred))

#accuracy of all models
lr_accuracy = accuracy_score(y_test, lr_pred)
dt_model = accuracy_score(y_test, dt_pred)
nn_accuracy = accuracy_score(y_test, nn_pred)

models= ["Logistic Regression","Decision Tree", "Neural Network"]
accuracy_scores = [lr_accuracy, dt_model, nn_accuracy]

#bar plot
plt.figure(figsize=(10, 6))
plt.bar(models, accuracy_scores, color=['darkred', 'purple', 'black'])
plt.ylim(0, 1)  # Accuracy is between 0 and 1
plt.ylabel('Accuracy')
plt.title('Model Accuracy Comparison')
plt.show()

"""Precision and recall comparison"""

print("Model Precision:")
lr_precision=precision_score(y_test, lr_pred)
dt_precision = precision_score(y_test, dt_pred)
nn_precision=precision_score(y_test, nn_pred)
models=["Logistic Regression","Decision Tree", "Neural Network"]
precision_scores=[lr_accuracy, dt_model, nn_accuracy]
print(f"logistic regression {lr_precision}, decession tree {dt_precision}, neural network {nn_precision}")
plt.figure(figsize=(10, 6))
plt.bar(models, precision_scores, color=['darkred', 'purple', 'black'])
plt.ylim(0, 1)
plt.ylabel('Precision')
plt.xlabel('Models')
plt.title('Model precision Comparison')
plt.show()

print("Model Recall:")
lr_recall=recall_score(y_test, lr_pred)
dt_recall = recall_score(y_test, dt_pred)
nn_recall=recall_score(y_test, nn_pred)
models=["Logistic Regression","Decision Tree", "Neural Network"]
recall_scores=[lr_recall, dt_recall, nn_recall]
print(f"logistic regression {lr_recall}, decession tree {dt_recall}, neural network {nn_recall}")
plt.figure(figsize=(10, 6))
plt.bar(models, recall_scores, color=['darkred', 'purple', 'black'])
plt.ylim(0, 1)
plt.ylabel('Recall')
plt.xlabel('Models')
plt.title('Model Recall Comparison')
plt.show()

"""Model selection/Comparison analysis
Bar chart showcasing prediction accuracy of all models (for classification)
Precision, recall comparison of each model. (for classification)
Confusion Matrix (for classification)
AUC score, ROC curve for each model (for classification)
R2 score and Loss  (for regression)

Confusion Matrix
"""

class_labels = np.unique(y_test)
lr_CM = confusion_matrix(y_test, lr_pred)
ConfusionMatrixDisplay(lr_CM, display_labels=class_labels).plot(cmap="Blues")
plt.title("Logistic Regression Confusion Matrix")
plt.show()

class_labels = np.unique(y_test)
dt_CM = confusion_matrix(y_test, dt_pred)
ConfusionMatrixDisplay(dt_CM, display_labels=class_labels).plot(cmap="Blues")
plt.title("Decision Tree Confusion Matrix")
plt.show()

class_labels = np.unique(y_test)
nn_CM = confusion_matrix(y_test, nn_pred)
ConfusionMatrixDisplay(nn_CM, display_labels=class_labels).plot(cmap="Blues")
plt.title("Neural Network Confusion Matrix")
plt.show()

"""AUC score and ROC curve"""



# Gather model results
model_results = {}

# Decision Tree
model_results['Decision Tree'] = {
    'accuracy': accuracy_score(y_test, dt_pred),
    'precision': precision_score(y_test, dt_pred),
    'recall': recall_score(y_test, dt_pred),
    'conf_matrix': confusion_matrix(y_test, dt_pred)
}

# Random Forest


# Neural Network
model_results['Neural Network'] = {
    'accuracy': accuracy_score(y_test, nn_pred),
    'precision': precision_score(y_test, nn_pred),
    'recall': recall_score(y_test, nn_pred),
    'conf_matrix': confusion_matrix(y_test, nn_pred)
}

# Logistic Regression
model_results['Logistic Regression'] = {
    'accuracy': accuracy_score(y_test, lr_pred),
    'precision': precision_score(y_test, lr_pred),
    'recall': recall_score(y_test, lr_pred),
    'conf_matrix': confusion_matrix(y_test, lr_pred)
}

for model_name, metrics in model_results.items():
    print(f"{model_name}:")
    print(f"  Accuracy: {metrics['accuracy']:.4f}")
    print(f"  Precision: {metrics['precision']:.4f}")
    print(f"  Recall: {metrics['recall']:.4f}")
    print(f"  Confusion Matrix:\n{metrics['conf_matrix']}")
    print("-" * 30)